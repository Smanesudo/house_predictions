{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- Distribution of variables (features and labels): outliers, imbalancement?\n",
    "- Missing values\n",
    "- Correlation\n",
    "- Categorical variables: ordinal, nominal, many distinct values, method of encoding ?\n",
    "- Numerical variables: agregation between variables (sum, mean, percentage ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape) #1460 observations, 81 variables: features + label = SalePrice\n",
    "print(test.shape) #1459 observations, 80 variables features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "def analyse_data(data):\n",
    "    \n",
    "    display(data.head(n=5))\n",
    "    \n",
    "    liste_colonnes = data.columns\n",
    "    print(\"Dimensions:\", data.shape)\n",
    "    print('\\n')\n",
    "    \n",
    "    cat_non_numerical = []\n",
    "    for i, col in enumerate(liste_colonnes) :\n",
    "        print(\"Colonne n°{}: {}\".format(i, col))\n",
    "        print('-'*30)\n",
    "        print(\"Type de la colonne:\", data[col].dtype)\n",
    "        print(\"Nb de valeurs uniques:\", len(data[col].unique()))\n",
    "        print(\"Comptage des valeurs:\")\n",
    "        print(data[col].value_counts(dropna=False))\n",
    "        percentage_NaN = data[col].isna().sum()/len(data)*100\n",
    "        print(\"Pourcentage de NaN: {}%\".format(percentage_NaN))\n",
    "\n",
    "        print('\\n')\n",
    "        print('*'*50)\n",
    "        print('\\n')\n",
    "        \n",
    "        if data[col].dtype == 'object':\n",
    "            cat_non_numerical.append(col)\n",
    "    \n",
    "    #return cols_a_garder, pourcentage_cols_a_garder\n",
    "    return cat_non_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_non_numerical_train = analyse_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_non_numerical_test = analyse_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_non_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['MoSold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- MSSubClass: nominal variable\n",
    "- MSZoning: nominal variable\n",
    "- LotArea: 215k outlier ?\n",
    "- Street: nominal variable, Enlever la variable ?\n",
    "- Alley: nominal variable, Remplacer NaN par une valeur ? \n",
    "- LotShape: nominal variable\n",
    "- LandContour: nominal variable\n",
    "- Utilities: nominal variable, suppression de la variable ?\n",
    "- LotConfig: nominal variable\n",
    "- LandSlope: ordinal variable\n",
    "- Neighborhood: nominal variable\n",
    "- Condition1: nominal variable\n",
    "- Condition2: nominal variable, déséquilibre distribution: suppression variable ? \n",
    "- BldgType: nominal variable\n",
    "- HouseStyle: nominal variable     \n",
    "- OverallQual: ordinal variable\n",
    "- OverallCond:  ordinal variable\n",
    "    regarder corrélation avec chi2, pearson avec OverallQual\n",
    "YearBuilt: transformer en durée\n",
    "YearRemodAdd: transformer en durée, corrélation avec YearBuilt\n",
    "RoofStyle: nominal variable\n",
    "RoofMatl: nominal variable\n",
    "Exterior1st: nominal variable\n",
    "Exterior2nd: nominal variable\n",
    "MasVnrType: nominal variablen, Presence de None et de Nan, est-ce que la même chose ou c'est différent ?\n",
    "MasVnrArea: numérique, Présence de NaN\n",
    "ExterQual: ordinal variable\n",
    "ExterCond:  ordinal variable\n",
    "Foundation:  nominal variable\n",
    "BsmtQual: ordinal variable, NaN\n",
    "BsmtCond: ordinal variable, NaN\n",
    "BsmtExposure: ordinal variable, NaN\n",
    "BsmtFinType1: ordinal variable, NaN\n",
    "BsmtFinSF1: continuous,  énormément de 0, distribution déséquilibrée\n",
    "BsmtFinType2:  ordinal variable, NaN\n",
    "BsmtFinSF2: continuous, énormément de 0, distribution déséquilibrée\n",
    "BsmtUnfSF: continuous\n",
    "TotalBsmtSF: continuous, à mettre ensemble avec BsmtUnfSF en pourcentage ?\n",
    "Heating: nominal variable, distribution déséquilibrée\n",
    "HeatingQC: ordinal variable\n",
    "CentralAir: binary variable string, distribution déséquilibrée, label encoding ?\n",
    "Electrical: ordinal or nominal variable ?, 1 seul NaN,  distribution déséquilibrée, label encoding\n",
    "1stFlrSF: continuous\n",
    "2ndFlrSF: continuous, distribution déséquilibrée\n",
    "LowQualFinSF: continuous, distribution déséquilibrée, faire somme avec 1stFlrSF et 2ndFlrSF\n",
    "GrLivArea: continuous, on peut ptet l'utiliser avec 1stFlrSF et 2ndFlrSF\n",
    "BsmtFullBath: numérique\n",
    "BsmtHalfBath: numérique, distribution déséquilibrée\n",
    "FullBath: numérique\n",
    "HalfBath: numérique\n",
    "Bedroom: numerical variable\n",
    "Kitchen: numerical variable\n",
    "KitchenQual: ordinal variable\n",
    "TotRmsAbvGrd: numerical variable\n",
    "Functional: nominal variable\n",
    "Fireplaces: numerical variable\n",
    "FireplaceQu: ordinal variable, NaN   = pas de cheminée\n",
    "GarageType:  nominal variable, NaN = No Garage\n",
    "GarageYrBlt: transformer en durée, il y a des NaN\n",
    "GarageFinish: nominal variable, NaN = no garage\n",
    "GarageCars: continuous\n",
    "GarageArea: continuous\n",
    "GarageQual: ordinal, NaN, distribution déséquilibrée\n",
    "GarageCond: ordinal, NaN, distribution déséquilibrée\n",
    "PavedDrive: nominal,  distribution déséquilibrée\n",
    "WoodDeckSF: continuous\n",
    "OpenPorchSF: continuous,distribution déséquilibrée\n",
    "EnclosedPorch : continuous,distribution déséquilibrée   \n",
    "3SsnPorch: continuous, distribution déséquilibrée   \n",
    "ScreenPorch: continuous, distribution déséquilibrée \n",
    "PoolArea:continuous, distribution déséquilibrée \n",
    "PoolQC: ordinal, bcp de NaN = No Pool\n",
    "Fence: ordinal, bcp de NaN = No Fence\n",
    "MiscFeature: nominal, bcp de NaN = None\n",
    "MiscVal: continuous, bcp de 0\n",
    "MoSold: nominal or ordinal (mois) à transformer en durée ?\n",
    "YrSold: nominal or ordinal(année) à transformer en durée ?\n",
    "SaleType: nominal, distribution déséquilibrée  \n",
    "SaleCondition: nominal, distribution déséquilibrée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III - Features Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Ordinal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['ExterQual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding for ordinal variables\n",
    "#from sklearn import preprocessing\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#OrdinalFeature = 'ExterQual'#\n",
    "#train[OrdinalFeature+ 'Encoded'] = le.fit_transform(train['ExterQual'])\n",
    "#train2 = train.drop(OrdinalFeature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le.classes_\n",
    "#How LabelEncoder choose the order to encode the distinct values ?\n",
    "#In the case of strings, LabelEncoder sorts alphabetically the distinct values and then it assign values from 0 to N\n",
    "\n",
    "#With Label Encoding we have this following order: \n",
    "#['Ex', 'Fa', 'Gd', 'TA'] = [0,1,2,3]\n",
    "#The correct order according to the data_description is:\n",
    "#       Ex\tExcellent\n",
    "#       Gd\tGood\n",
    "#       TA\tAverage/Typical\n",
    "#       Fa\tFair\n",
    "#       Po\tPoor\n",
    "#so we must have Po < Fa < TA < Gd < Ex => ['Po', 'Fa', 'TA', 'Gd', 'Ex']  = [0,1,2,3,4]\n",
    "#But Po doesn't exist in our data, so we have : \n",
    "#['Fa', 'TA', 'Gd', 'Ex'] = [0,1,2,3]\n",
    "\n",
    "#Should we use the order of LabelEncoder or the order of the data description ?\n",
    "#There is a difference for the algorithm ?\n",
    "#If yes, so we have to create our own LabelEncoder for using the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.copy()\n",
    "test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['ExterQual'].value_counts())\n",
    "print(test['ExterQual'].value_counts())\n",
    "print(train['ExterCond'].value_counts())\n",
    "print(test['ExterCond'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "#Same thing like LabelEncoder but we can apply for many features at the same time\n",
    "#But it works only with at least 2 features\n",
    "#We choose our own order by adding the argument categories and write all the categories in a list for each feature\n",
    "OrdinalFeatures = ['ExterQual','ExterCond']\n",
    "enc = OrdinalEncoder(dtype = 'int32', categories = [['Fa', 'TA', 'Gd', 'Ex'],['Po','Fa', 'TA', 'Gd', 'Ex']])\n",
    "train[OrdinalFeatures] = enc.fit_transform(train[OrdinalFeatures])\n",
    "test[OrdinalFeatures] = enc.transform(test[OrdinalFeatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With automatic order\n",
    "enc2 = OrdinalEncoder(dtype = 'int32')\n",
    "train[OrdinalFeatures] = enc2.fit_transform(train[OrdinalFeatures])\n",
    "test[OrdinalFeatures] = enc2.transform(test[OrdinalFeatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[OrdinalFeatures].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[OrdinalFeatures].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[OrdinalFeatures].head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X =  train.drop('SalePrice', axis = 1)\n",
    "X = train[OrdinalFeatures]\n",
    "y = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(None, dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4c7171e9fd04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mestimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enc '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOrdinalFeatures\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOrdinalFeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOrdinalFeatures\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOrdinalFeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 142\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array array(None, dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "OrdinalFeatures = ['ExterQual','ExterCond']\n",
    "enc = OrdinalEncoder(dtype = 'int32', categories = [['Fa', 'TA', 'Gd', 'Ex'],['Po','Fa', 'TA', 'Gd', 'Ex']])\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "estimators = [('enc ', enc), ('clf', clf )]\n",
    "pipe = Pipeline(estimators)\n",
    "train[OrdinalFeatures] = pipe.fit_transform(train[OrdinalFeatures])\n",
    "test[OrdinalFeatures] = pipe.transform(test[OrdinalFeatures])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
